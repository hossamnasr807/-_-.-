{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hossa\\appdata\\roaming\\python\\python311\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: torch in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hossa\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hossa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchvision-0.18.0-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.2 MB 640.0 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.2 MB 653.6 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.3/1.2 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.7/1.2 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.8/1.2 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy opencv-python torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "# Clone the YOLOv5 repository and install dependencies\n",
    "git clone https://github.com/ultralytics/yolov5\n",
    "cd yolov5\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hossa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\hossa/.cache\\torch\\hub\\master.zip\n",
      "c:\\Users\\hossa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "YOLOv5  2024-6-1 Python-3.11.7 torch-2.3.0+cpu CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:04<00:00, 3.64MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5l, yolov5x depending on your need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(0)  # Change '0' to the path of your video file\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for result in results.xyxy[0].numpy():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection and Tracking', frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sort (from versions: none)\n",
      "ERROR: No matching distribution found for sort\n"
     ]
    }
   ],
   "source": [
    "# Install the SORT tracking algorithm\n",
    "!pip install sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Sort' from 'sort' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sort\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the SORT tracker\u001b[39;00m\n\u001b[0;32m      4\u001b[0m tracker \u001b[38;5;241m=\u001b[39m Sort()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Sort' from 'sort' (unknown location)"
     ]
    }
   ],
   "source": [
    "from sort import Sort\n",
    "\n",
    "# Initialize the SORT tracker\n",
    "tracker = Sort()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Prepare detection data for SORT\n",
    "    detections = []\n",
    "    for result in results.xyxy[0].numpy():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        detections.append([x1, y1, x2, y2, conf])\n",
    "\n",
    "    # Update tracker with detections\n",
    "    trackers = tracker.update(np.array(detections))\n",
    "\n",
    "    # Draw bounding boxes with IDs on the frame\n",
    "    for d in trackers:\n",
    "        x1, y1, x2, y2, obj_id = d\n",
    "        label = f\"ID {int(obj_id)}\"\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection and Tracking', frame)\n",
    "\n",
    "    # Break loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
